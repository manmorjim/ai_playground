{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Word2vec.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manmorjim/ai_playground/blob/main/somos_nlp/nlp_0_100/1_word_embeddings/word2vec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XvNCXd9Dfqe1"
      },
      "source": [
        "# Word2vec con Gensim\n",
        "\n",
        "En este cuaderno de Jupyter vas a utilizar la biblioteca [Gensim](https://radimrehurek.com/gensim/index.html) para experimentar con word2vec. Este cuaderno está enfocado en la intuición de los conceptos y no en los detalles de implementación. Este cuaderno está inspirado en esta [guía](https://radimrehurek.com/gensim/auto_examples/tutorials/run_word2vec.html).\n",
        "\n",
        "## 1. Instalación y cargar el modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKIqnDXXfpiz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13eee770-a26f-4003-f783-c46342ab2688"
      },
      "source": [
        "!pip install --upgrade gensim"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.1)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.10.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (6.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sn7Q2jB3frOn"
      },
      "source": [
        "import gensim.downloader as api"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBaT8djWkaZy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cc36b67-ce6f-41be-bced-86b3245e6047"
      },
      "source": [
        "model = api.load('word2vec-google-news-300')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[=================================================-] 99.9% 1661.9/1662.8MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVZm7iTOoawW"
      },
      "source": [
        "## 2. Similitud de palabras\n",
        "\n",
        "En esta sección veremos cómo conseguir la similitud entre dos palabras utilizando un word embedding ya entrenado."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOZfaelLoi4c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4056b93a-4158-4f0c-f8ed-19c512c97aa2"
      },
      "source": [
        "model.similarity(\"king\", \"queen\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6510957"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BX-Kk9HZofuF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f27e9283-5a4b-462c-9d28-b08a8aa97c2f"
      },
      "source": [
        "model.similarity(\"king\", \"man\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.22942673"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypFK-pLrol3N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c9d2931-c6fe-4cf0-d634-ac5838151159"
      },
      "source": [
        "model.similarity(\"king\", \"potato\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.09978465"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBWzZySFormq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49498369-8e7a-4973-d51d-b87a3cdee10f"
      },
      "source": [
        "model.similarity(\"king\", \"king\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9GijWs_tx83W"
      },
      "source": [
        "Ahora veremos cómo encontrar las palabras con mayor similitud al conjunto de palabras especificado."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytELAWBLk2-6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a53b7dc5-9b6c-4472-9aa8-d740ae6ad7f1"
      },
      "source": [
        "model.most_similar([\"king\", \"queen\"], topn=5)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('monarch', 0.7042067050933838),\n",
              " ('kings', 0.6780861616134644),\n",
              " ('princess', 0.6731551885604858),\n",
              " ('queens', 0.6679497957229614),\n",
              " ('prince', 0.6435247659683228)]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7D4ZS7N3ovxB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ca689b2-801d-414e-c341-a54526fda9a6"
      },
      "source": [
        "model.most_similar([\"tomato\", \"carrot\"], topn=5)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('carrots', 0.7536594867706299),\n",
              " ('tomatoes', 0.7129638195037842),\n",
              " ('celery', 0.7025030851364136),\n",
              " ('broccoli', 0.6796350479125977),\n",
              " ('cherry_tomatoes', 0.662927508354187)]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZFlxKjOyBpu"
      },
      "source": [
        "Pero incluso puedes hacer cosas interesantes como ver qué palabra no corresponde a una lista."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CrZdcBpn3pn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c842b93a-273a-4125-d23a-0d468ac57d5f"
      },
      "source": [
        "model.doesnt_match([\"summer\", \"fall\", \"spring\", \"air\"])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'air'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ko09hZ3dqMZ1"
      },
      "source": [
        "## Ejercicios\n",
        "\n",
        "1. Usa el modelo word2vec para hacer un ranking de las siguientes 15 palabras según su similitud con las palabras \"man\" y \"woman\". Para cada par, imprime su similitud."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "common_words_man = model.most_similar(['man'], topn=15)\n",
        "common_words_woman = model.most_similar(['woman'], topn=15)\n",
        "\n",
        "for m, w in zip(common_words_man, common_words_woman):\n",
        "  print(m, w)"
      ],
      "metadata": {
        "id": "t-faweq7AYEE",
        "outputId": "acf05817-a558-4e57-9e8a-ea5d28420432",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('woman', 0.7664012908935547) ('man', 0.7664012908935547)\n",
            "('boy', 0.6824871301651001) ('girl', 0.7494640946388245)\n",
            "('teenager', 0.6586930155754089) ('teenage_girl', 0.7336829304695129)\n",
            "('teenage_girl', 0.6147903203964233) ('teenager', 0.6317085027694702)\n",
            "('girl', 0.5921714305877686) ('lady', 0.6288785934448242)\n",
            "('suspected_purse_snatcher', 0.571636438369751) ('teenaged_girl', 0.6141784191131592)\n",
            "('robber', 0.5585119128227234) ('mother', 0.6076306104660034)\n",
            "('Robbery_suspect', 0.5584409832954407) ('policewoman', 0.6069462299346924)\n",
            "('teen_ager', 0.5549196600914001) ('boy', 0.5975907444953918)\n",
            "('men', 0.5489763021469116) ('Woman', 0.5770983099937439)\n",
            "('horribly_horribly_deranged', 0.5426712036132812) ('sexually_assualted', 0.5723768472671509)\n",
            "('guy', 0.5420035123825073) ('she', 0.5641393661499023)\n",
            "('person', 0.5342026352882385) ('Leah_Questin', 0.5481955409049988)\n",
            "('gentleman', 0.5337990522384644) ('WOMAN', 0.5480420589447021)\n",
            "('knife_wielding_thief', 0.5337865352630615) ('person', 0.5470173358917236)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzZ1eD3PpT-d"
      },
      "source": [
        "words = [\n",
        "\"wife\",\n",
        "\"husband\",\n",
        "\"child\",\n",
        "\"queen\",\n",
        "\"king\",\n",
        "\"man\",\n",
        "\"woman\",\n",
        "\"birth\",\n",
        "\"doctor\",\n",
        "\"nurse\",\n",
        "\"teacher\",\n",
        "\"professor\",\n",
        "\"engineer\",\n",
        "\"scientist\",\n",
        "\"president\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKamywnxqxJJ"
      },
      "source": [
        "**2. Completa las siguientes analogías por tu cuenta (sin usar el modelo)**\n",
        "\n",
        "a. king is to throne as judge is to _ *tribune*\n",
        "\n",
        "b. giant is to dwarf as genius is to _ *stupid*\n",
        "\n",
        "c. French is to France as Spaniard is to _ *Spain*\n",
        "\n",
        "d. bad is to good as sad is to _ *happy*\n",
        "\n",
        "e. nurse is to hospital as teacher is to _ *school*\n",
        "\n",
        "f. universe is to planet as house is to _ *furniture*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VcNRxHuZrXAM"
      },
      "source": [
        "**3. Ahora completa las analogías usando un modelo word2vec**\n",
        "\n",
        "Aquí hay un ejemplo de cómo hacerlo. Puedes resolver analogías como \"A es a B como C es a _\" haciendo B + C - A. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4kF08h4qhxM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "098b0d8f-5072-4a65-e54f-e9de7ab900b5"
      },
      "source": [
        "# man is to woman as king is to ___?\n",
        "model.most_similar(positive=[\"king\", \"woman\"], negative=[\"man\"], topn=1)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('queen', 0.7118193507194519)]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DiPbbGsori48",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f852bae-f70d-41cb-ab85-b34970b7c8e0"
      },
      "source": [
        "# us is to burger as italy is to ___?\n",
        "model.most_similar(positive=[\"Italy\", \"burger\"], negative=[\"USA\"], topn=1)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('panino', 0.5671379566192627)]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# king is to throne as judge is to _\n",
        "model.most_similar(positive=[\"throne\", \"judge\"], negative=[\"king\"], topn=1)"
      ],
      "metadata": {
        "id": "pxkSN-FNEvvf",
        "outputId": "81fc63c2-486c-4953-e673-3d91833aa00e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('appellate_court', 0.5845253467559814)]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# giant is to dwarf as genius is to _\n",
        "model.most_similar(positive=[\"dwarf\", \"genius\"], negative=[\"giant\"], topn=1)"
      ],
      "metadata": {
        "id": "iVlbU3cHGJzh",
        "outputId": "5fac5475-9514-412a-f0eb-569370871228",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('savant', 0.44152510166168213)]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# French is to France as Spaniard is to _\n",
        "model.most_similar(positive=[\"France\", \"Spaniard\"], negative=[\"French\"], topn=1)"
      ],
      "metadata": {
        "id": "2mCg2KycGMZs",
        "outputId": "51a786e4-0439-405d-970c-2edf1ddae2e9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('rider_Dani_Pedrosa', 0.5646752119064331)]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# bad is to good as sad is to _\n",
        "model.most_similar(positive=[\"good\", \"sad\"], negative=[\"bad\"], topn=1)"
      ],
      "metadata": {
        "id": "gztfOXzlGewo",
        "outputId": "5d492e88-cf19-418d-c7db-3402d5a3328c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('wonderful', 0.6414927840232849)]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# nurse is to hospital as teacher is to _\n",
        "model.most_similar(positive=[\"hospital\", \"teacher\"], negative=[\"nurse\"], topn=1)"
      ],
      "metadata": {
        "id": "NXUwmSKkGhXL",
        "outputId": "059e9ed8-e2b0-4e0d-aa4d-0d1d2fed996b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('school', 0.60170978307724)]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# universe is to planet as house is to _\n",
        "model.most_similar(positive=[\"planet\", \"house\"], negative=[\"universe\"], topn=1)"
      ],
      "metadata": {
        "id": "kwbZLLxkGkZC",
        "outputId": "aec5bc87-c236-4f84-e3cb-4055e0fbe679",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('bungalow', 0.5428240299224854)]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    }
  ]
}